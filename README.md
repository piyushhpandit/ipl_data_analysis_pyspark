IPL Data Analysis Pipeline (2008-2017)


üèè Project Overview

This project implements a comprehensive data analytics pipeline for Indian Premier League (IPL) cricket data spanning from 2008 to 2017. Built using Apache Spark and PySpark on Databricks, the pipeline processes and analyzes multiple seasons of cricket data to extract meaningful insights about player performance, team strategies, and match outcomes.


üéØ Objectives
	‚Ä¢	Performance Analytics: Analyze individual player and team performance across multiple seasons
	‚Ä¢	Strategic Insights: Understand the impact of toss decisions, venue conditions, and match dynamics
	‚Ä¢	Data-Driven Discoveries: Identify patterns in dismissal types, powerplay performance, and winning strategies
	‚Ä¢	Scalable Processing: Handle large-scale cricket datasets efficiently using distributed computing


üèóÔ∏è Architecture


![Archittecture](https://github.com/user-attachments/assets/8360e88c-ae87-40d7-9ba3-9c5ef4d2ebb1)


üìä Data Sources


The pipeline processes five main datasets:

1. Ball_By_Ball (48 columns)
	‚Ä¢	Detailed ball-by-ball information for every delivery
	‚Ä¢	Includes runs scored, extras, dismissals, and player details
	‚Ä¢	Key Fields: match_id, over_id, runs_scored, striker, bowler, wicket_info

2. Match (17 columns)
	‚Ä¢	Match-level information including teams, venues, and outcomes
	‚Ä¢	Contains toss decisions and match winners
	‚Ä¢	Key Fields: match_id, team1, team2, venue_name, toss_winner, match_winner

3. Player (7 columns)
	‚Ä¢	Player master data with personal information
	‚Ä¢	Key Fields: player_id, player_name, batting_hand, bowling_skill

4. Player_Match (22 columns)
	‚Ä¢	Player participation and role information for each match
	‚Ä¢	Key Fields: match_id, player_id, role_desc, is_manofthematch

5. Team (3 columns)
	‚Ä¢	Team master data
	‚Ä¢	Key Fields: team_id, team_name

üîß Technical Implementation

Data Processing Pipeline

1. Schema Definition & Data Loading

# Structured schema definition for type safety

ball_by_ball_schema = StructType([
    StructField("match_id", IntegerType(), True),
    StructField("runs_scored", IntegerType(), True),
    # ... additional fields
])

# Loading data from S3 with predefined schema

ball_by_ball_df = spark.read.schema(ball_by_ball_schema)\
    .format('csv').option('header', 'true')\
    .load("s3://ipl-data-analysis-project/Ball_By_Ball.csv")

2. Data Cleaning & Transformation
	‚Ä¢	Filtering: Remove invalid deliveries (wides, no-balls) for accurate analysis
	‚Ä¢	Normalization: Clean player names and handle missing values
	‚Ä¢	Feature Engineering: Create derived columns for advanced analytics

# Filter valid deliveries

ball_by_ball_df = ball_by_ball_df.filter(
    (col("wides") == 0) & (col("noballs") == 0)
)

# Create high-impact ball indicator

ball_by_ball_df = ball_by_ball_df.withColumn(
    "high_impact",
    when((col("runs_scored") + col("extra_runs") > 6) | 
         (col("bowler_wicket") == True), True).otherwise(False)
)

3. Advanced Analytics Using Window Functions

# Running total calculation using window functions

windowSpec = Window.partitionBy("match_id","innings_no").orderBy("over_id")
ball_by_ball_df = ball_by_ball_df.withColumn(
    "running_total_runs",
    sum("runs_scored").over(windowSpec)
)

üìà Key Analytics & Insights

1. Top Scoring Batsmen Analysis
	‚Ä¢	Season-wise performance tracking
	‚Ä¢	Identifies consistent performers across multiple seasons
	‚Ä¢	SQL-based aggregation for scalable computation

SELECT p.player_name, m.season_year, SUM(b.runs_scored) AS total_runs 
FROM ball_by_ball b
JOIN match m ON b.match_id = m.match_id   
JOIN player_match pm ON m.match_id = pm.match_id AND b.striker = pm.player_id     
JOIN player p ON p.player_id = pm.player_id
GROUP BY p.player_name, m.season_year
ORDER BY m.season_year, total_runs DESC

2. Powerplay Bowling Economy
Ôøº
	‚Ä¢	Analyzes bowler performance in crucial first 6 overs
	‚Ä¢	Economy rate calculation with wicket-taking ability
	‚Ä¢	Identifies most effective powerplay bowlers

3. Toss Impact Analysis
Ôøº
	‚Ä¢	Statistical analysis of toss decision impact on match outcomes
	‚Ä¢	Team-wise performance after winning toss
	‚Ä¢	Strategic insights for captains

4. Venue-Based Performance
Ôøº
	‚Ä¢	Average and highest scores by venue
	‚Ä¢	Identifies batting-friendly vs bowling-friendly grounds
	‚Ä¢	Helps in team selection and strategy planning

5. Dismissal Pattern Analysis
Ôøº
	‚Ä¢	Frequency analysis of different dismissal types
	‚Ä¢	Bowler effectiveness metrics
	‚Ä¢	Batting vulnerabilities identification

üöÄ Key Features

Distributed Computing
	‚Ä¢	Leverages Spark's distributed processing for handling large datasets
	‚Ä¢	Efficient memory management and parallel processing
	‚Ä¢	Scalable architecture supporting growing data volumes

Data Quality Assurance
	‚Ä¢	Comprehensive schema validation
	‚Ä¢	Missing value handling and data type enforcement
	‚Ä¢	Duplicate detection and removal processes

Advanced Analytics
	‚Ä¢	Window functions for running calculations
	‚Ä¢	Complex joins across multiple datasets
	‚Ä¢	Statistical aggregations and trend analysis

Interactive Visualizations
	‚Ä¢	Matplotlib and Seaborn integration
	‚Ä¢	Comprehensive charts and plots
	‚Ä¢	Data-driven storytelling capabilities

üõ†Ô∏è Technologies Used
	‚Ä¢	Big Data Processing: Apache Spark, PySpark
	‚Ä¢	Cloud Platform: Databricks, AWS S3
	‚Ä¢	Data Storage: Distributed file system (S3)
	‚Ä¢	Analytics: Spark SQL, Spark MLlib
	‚Ä¢	Visualization: Matplotlib, Seaborn, Pandas
	‚Ä¢	Languages: Python, SQL

üìä Sample Insights Generated

Performance Metrics
	‚Ä¢	Most Consistent Batsmen: Season-wise run aggregations
	‚Ä¢	Most Economical Bowlers: Powerplay economy rates
	‚Ä¢	Venue Impact: Home ground advantages and pitch conditions
	‚Ä¢	Toss Strategy: Win percentage correlation with toss decisions

Strategic Intelligence
	‚Ä¢	Match-Winning Patterns: Factors contributing to victory
	‚Ä¢	Player Impact: Individual player contributions to team success
	‚Ä¢	Temporal Trends: Performance evolution over multiple seasons

üéØ Business Value
	1	Team Strategy Optimization: Data-driven insights for team selection and match strategies
	2	Player Performance Evaluation: Comprehensive player assessment for auctions and trades
	3	Fan Engagement: Statistical insights for enhanced viewing experience
	4	Predictive Analytics Foundation: Prepared datasets for machine learning models

üîú Future Enhancements
	‚Ä¢	Machine Learning Models: Predictive modeling for match outcomes
	‚Ä¢	Real-time Analytics: Streaming data processing capabilities
	‚Ä¢	Advanced Visualizations: Interactive dashboards using Plotly/Dash
	‚Ä¢	Player Recommendation System: ML-based player selection optimization
 
üö¶ Getting Started
	1	Setup Databricks Environment
	2	Configure AWS S3 Access
	3	Load Data to S3 Bucket
	4	Import Notebooks to Databricks
	5	Execute Data Pipeline
	6	Generate Analytics Reports


This project demonstrates the power of big data analytics in sports, providing actionable insights that can transform how cricket teams strategize and perform. The scalable architecture ensures the pipeline can handle growing datasets and evolving analytical requirements.
